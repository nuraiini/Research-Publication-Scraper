# ğŸ§ª Web Scraping Publikasi Ilmiah: Scopus, Google Scholar, dan SINTA

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Selenium](https://img.shields.io/badge/Library-Selenium-green)
![SerpAPI](https://img.shields.io/badge/API-SerpAPI-orange)

## ğŸ‘¤ Author
**Nur'aini**
* ğŸ“ **Mahasiswa:** Program Studi Magister Statistika dan Sains Data, IPB University
* ğŸ“§ **Email:** Nuraiinii1001@gmail.com
* ğŸ”— **LinkedIn:** http://www.linkedin.com/in/nuraiinii01
---

## ğŸ“Œ Deskripsi Proyek
Repositori ini mendokumentasikan proses **web scraping data publikasi ilmiah** menggunakan Jupyter Notebook. Script ini mengintegrasikan tiga sumber data utama:
1.  **Scopus** (via Selenium + Firefox WebDriver)
2.  **Google Scholar** (via SerpAPI `google_scholar_author`)
3.  **SINTA Kemdikbud** (via Requests + BeautifulSoup)

ğŸ“¦ **Output:** Dataset publikasi dalam format **CSV** yang siap digunakan untuk dokumentasi akademik atau *literature review*.

---

## âœ¨ Fitur Utama

### 1) ğŸ§­ Scraping Scopus (Selenium)
Menggunakan **Selenium** dengan **Firefox (GeckoDriver)** untuk simulasi browser.
* **Otomatisasi:**
    * ğŸŒ Membuka Scopus & menangani *cookies*.
    * ğŸ” Login otomatis menggunakan kredensial tersimpan.
    * ğŸ‘¤ Navigasi menu Author & input nama target.
    * ğŸ“„ Ekstraksi tabel publikasi.
* **Output:** `outputs/scopus_data.csv`
* **Kolom:** `Article`, `Title`, `Authors`, `Journal`, `Year/Volume`, `Article URL`.
* **Fitur Debug:** Menyimpan *screenshot* otomatis jika terjadi error (misal: gagal login atau CAPTCHA).

### 2) ğŸ” Scraping Google Scholar (SerpAPI)
Menggunakan **SerpAPI** untuk mengatasi blokir anti-bot Google Scholar.
* **Fitur:**
    * ğŸ“„ Mengambil 100 artikel per halaman.
    * ğŸ” *Pagination* otomatis (0, 100, 200...).
    * ğŸ› ï¸ Sistem *retry* jika koneksi gagal.
    * ğŸ“Š Sorting artikel berdasarkan tahun terbaru.
* **Output:** `outputs/Google Scholar.csv`

### 3) ğŸ›ï¸ Scraping SINTA (Requests + BeautifulSoup)
Mengambil data langsung dari halaman profil SINTA (`sinta.kemdikbud.go.id`).
* **Data yang Diambil:**
    * ğŸ‘¤ **Profil:** Nama, Afiliasi, Prodi, SINTA Score.
    * ğŸ—‚ï¸ **Artikel:** Dari tab Google Scholar, Scopus, dan Garuda.
* **Output:** `outputs/sinta_profile_{id}.csv` & `outputs/sinta_articles_{id}.csv`
* **Keamanan:** Menggunakan rotasi *User-Agent* dan jeda waktu (*delay*) untuk mencegah pemblokiran.

---

## ğŸ—‚ï¸ Struktur Repositori

```text
.
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Nur'aini_M0501241058_Paralel_1.ipynb
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ scopus_data.csv
â”‚   â”œâ”€â”€ Google Scholar.csv
â”‚   â”œâ”€â”€ sinta_profile_6173018.csv
â”‚   â””â”€â”€ sinta_articles_6173018.csv
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Instalasi

### ğŸŸ¡ Opsi A â€” Google Colab (Termudah)
1.  Upload notebook ke Google Colab.
2.  Jalankan sel instalasi dependensi di awal notebook.
3.  Pastikan dependensi sistem (`firefox`, `geckodriver`) terinstal via `apt-get` (script sudah tersedia di notebook).

### ğŸŸ¢ Opsi B â€” Lokal (Windows/macOS/Linux)

#### 1. Buat Virtual Environment
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

#### 2. Install Library
```bash
pip install -r requirements.txt
```
*Isi file `requirements.txt` minimal:*
```text
selenium
pandas
requests
beautifulsoup4
google-search-results
```

#### 3. Driver Browser
Pastikan **Mozilla Firefox** dan **GeckoDriver** sudah terinstal dan terdaftar di PATH sistem komputer Anda.

---

## â–¶ï¸ Cara Menjalankan

1.  **Buka Jupyter Notebook:**
    ```bash
    jupyter notebook
    ```
2.  **Buka File:** Masuk ke folder `notebooks/` dan buka `Research_Publication_Scraper.ipynb`.
3.  **Eksekusi:** Jalankan sel secara berurutan:
    * ğŸ“¦ **Import Library**
    * ğŸ§­ **Scopus Section**
    * ğŸ” **Google Scholar Section**
    * ğŸ›ï¸ **SINTA Section**

---

## ğŸ” Konfigurasi (Wajib)

Demi keamanan, **JANGAN** tulis email/password langsung di kode. Gunakan *Environment Variables*.

### 1. Kredensial Scopus
Atur variabel lingkungan di terminal/OS Anda:
```bash
# Linux/macOS
export SCOPUS_EMAIL="nur.aiiniinuraini@apps.ipb.ac.id"
export SCOPUS_PASSWORD="password_anda"
```
*(Di Windows gunakan `set` atau edit System Environment Variables)*

### 2. SerpAPI Key
Dapatkan API Key dari [SerpAPI](https://serpapi.com/).
```bash
export SERPAPI_KEY="api_key_anda"
```

### 3. ID Target (Di dalam Notebook)
Sesuaikan variabel berikut pada kode notebook:
* **Google Scholar:** `author_id = "apmXydQAAAAJ"`
* **SINTA:** `author_id = "6173018"`
* **Scopus:** Input nama depan & belakang pada fungsi input Selenium.

---

## ğŸ§¯ Troubleshooting

Berikut adalah solusi untuk masalah umum yang sering terjadi saat scraping:

| Modul | Masalah | Solusi Potensial |
| :--- | :--- | :--- |
| **ğŸ§­ Scopus** | **Login Gagal / CAPTCHA** | â€¢ Ganti koneksi internet (IP berbeda).<br>â€¢ Tambah durasi `time.sleep()` pada kode.<br>â€¢ Coba login manual sekali di browser.<br>â€¢ Pastikan akun memiliki akses langganan institusi. |
| **ğŸ§· Selenium** | **GeckoDriver Not Found** | â€¢ Pastikan `geckodriver` terinstal.<br>â€¢ Cek apakah path driver sudah benar.<br>â€¢ Pastikan versi Firefox kompatibel dengan driver. |
| **ğŸ” SerpAPI** | **No Result / Kuota Habis** | â€¢ Cek sisa kuota di dashboard SerpAPI.<br>â€¢ Pastikan `author_id` valid dan benar. |
| **ğŸ›ï¸ SINTA** | **Request Timeout** | â€¢ Naikkan parameter `timeout` pada `requests.get`.<br>â€¢ Perbesar jeda waktu (*delay*) antar request. |

---

## âœ… Etika & Kepatuhan

1.  **Terms of Service:** Patuhi aturan penggunaan (*Terms of Service*) dan `robots.txt` dari Scopus, Google Scholar, dan SINTA.
2.  **Hak Cipta:** Data yang diambil mungkin memiliki hak cipta. Gunakan hanya untuk keperluan dokumentasi pribadi atau riset akademik.
3.  **Rate Limiting:** Script ini menerapkan *delay* (jeda) antar permintaan untuk menghormati beban server target. Jangan menghilangkan *delay* tersebut.
